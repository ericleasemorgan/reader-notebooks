{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More feature extraction: Textacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Natural Language Toolkit is the grand daddy of text mining libraries/modules for Python, but since its inception, other tools have made themeselves available. One of those tools is called \"Textacy\". Textacy does many of the things done by the NLTK, and it does more. This extra functionality is both more complicated and more expressive than the 'Toolkit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configure\n",
    "FILE    = './texts/shakespeare-sonnets.txt'\n",
    "KEYWORD = 'love'\n",
    "MODEL   = 'en_core_web_sm'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# require\n",
    "import textacy\n",
    "import os\n",
    "import spacy\n",
    "from textacy.ke import yake\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slurp up some plain text...\n",
    "data = open( FILE ).read()\n",
    "\n",
    "# ...and do the tiniest bit of normalization (\"cleaning\") against it\n",
    "data = data.replace( '\\n', ' ' ).replace( '\\t', ' ').replace( '  ', ' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# perform a keyword in context (KWIC) query against the data; concordance\n",
    "#result = textacy.text_utils.KWIC( data, KEYWORD )\n",
    "#print( list( result ) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a spaCy \"doc object\"; depending on the size of the input, this may take a few minutes to process\n",
    "size           = os.stat( FILE ).st_size\n",
    "nlp            = spacy.load( MODEL  )\n",
    "nlp.max_length = size \n",
    "doc            = nlp( data )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc._.preview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "textacy.TextStats( doc ).flesch_reading_ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(textacy.extract.ngrams( doc, 2, filter_stops=True, filter_punct=True, filter_nums=False) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yake( doc )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list( textacy.extract.entities( doc ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "list( textacy.extract.subject_verb_object_triples( doc ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list( textacy.extract.noun_chunks( doc ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list( textacy.extract.semistructured_statements( doc, entity='Jove', cue='be' ) ) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
